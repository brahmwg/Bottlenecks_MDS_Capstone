{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('vegafusion')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "from datetime import timedelta\n",
    "import numpy as np \n",
    "\n",
    "alt.data_transformers.enable(\"vegafusion\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is for concating the historical cowichan and 2021 onwards data into one file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sql(salmon2, cow, output_file):\n",
    "    # Filter and reset index for Cowichan watershed\n",
    "    salmon2_cow_temp = salmon2[salmon2['watershed'] == 'cowichan'].reset_index()\n",
    "    salmon2_cow = salmon2_cow_temp[['date', 'species', 'site', 'count']]\n",
    "    salmon2_cow = salmon2_cow[salmon2_cow['species'].isin(['co', 'ck'])]\n",
    "\n",
    "    # Create dummy variables for sites\n",
    "    site_dummies = pd.get_dummies(salmon2_cow['site'])\n",
    "    df_expanded = pd.concat([salmon2_cow, site_dummies], axis=1)\n",
    "    df_expanded = df_expanded.drop('site', axis=1)\n",
    "\n",
    "    # Standardize species names and concatenate datasets\n",
    "    cow['species'] = cow['species'].str.lower()\n",
    "    df_long = pd.concat([cow, df_expanded]).reset_index(drop=True)\n",
    "    df_long['species'] = df_long['species'].replace('cn', 'ck')\n",
    "\n",
    "    # Filter and create dummy variables for species\n",
    "    df_long_filter = df_long[df_long['species'].isin(['co', 'ck'])]\n",
    "    species_dummies = pd.get_dummies(df_long_filter['species'])\n",
    "    df_expanded_1 = pd.concat([df_long_filter, species_dummies], axis=1)\n",
    "    df_expanded_1 = df_expanded_1.drop('species', axis=1)\n",
    "\n",
    "    # Save the final dataframe to a CSV file\n",
    "    df_expanded_1.to_csv(output_file, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/salmon_concat.csv\n"
     ]
    }
   ],
   "source": [
    "salmon2 = pd.read_csv('data/data_salmon2.csv')  # Replace with the actual path to your salmon2 data\n",
    "cow = pd.read_csv('data/cowichan_historic.csv')  # Replace with the actual path to your cow data\n",
    "output_file = 'data/salmon_concat.csv'\n",
    "\n",
    "preprocess_sql(salmon2, cow, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mds_bottleneck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

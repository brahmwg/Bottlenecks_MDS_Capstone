{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(salmon_df_name, temp_df_name, level_df_name, flow_df_name):\n",
    "      df_salmon = pd.read_csv(f\"data/{salmon_df_name}\")[[\"date\", \"count\"]]\n",
    "      df_temp = pd.read_csv(f\"data/{temp_df_name}\")\n",
    "      df_level = pd.read_csv(f\"data/{level_df_name}\")\n",
    "      df_flow = pd.read_csv(f\"data/{flow_df_name}\")\n",
    "\n",
    "      df_salmon = df_salmon.groupby([\"date\"]).sum(\"count\")\n",
    "      df_salmon = df_salmon.reset_index()\n",
    "\n",
    "      flow_df_pivoted = df_flow.melt(id_vars=[\"STATION_NUMBER\", \"YEAR\", \"MONTH\"], var_name=\"Day\", value_name=\"Flow\")\n",
    "      flow_df_pivoted[\"Day\"] = flow_df_pivoted[\"Day\"].str.replace(\"FLOW\", \"\").astype(int)\n",
    "      flow_df_pivoted[\"Date\"] = flow_df_pivoted[\"YEAR\"].astype(str) + \"-\" + flow_df_pivoted[\"MONTH\"].astype(str) + \"-\" + flow_df_pivoted[\"Day\"].astype(str)\n",
    "      flow_df_pivoted[\"Date\"] = pd.to_datetime(flow_df_pivoted[\"Date\"], errors='coerce', format='mixed')\n",
    "      flow_df_pivoted = flow_df_pivoted.dropna(subset=[\"Date\"]).sort_values(by=\"Date\")\n",
    "      flow_df_pivoted = flow_df_pivoted.groupby(\"Date\").mean(\"Flow\").reset_index()\n",
    "\n",
    "      level_df_pivoted = df_level.melt(id_vars=[\"STATION_NUMBER\", \"YEAR\", \"MONTH\"], var_name=\"Day\", value_name=\"Level\")\n",
    "      level_df_pivoted[\"Day\"] = level_df_pivoted[\"Day\"].str.replace(\"LEVEL\", \"\").astype(int)\n",
    "      level_df_pivoted[\"Date\"] = level_df_pivoted[\"YEAR\"].astype(str) + \"-\" + level_df_pivoted[\"MONTH\"].astype(str) + \"-\" + level_df_pivoted[\"Day\"].astype(str)\n",
    "      level_df_pivoted[\"Date\"] = pd.to_datetime(level_df_pivoted[\"Date\"], errors='coerce', format='mixed')\n",
    "      level_df_pivoted = level_df_pivoted.dropna(subset=[\"Date\"]).sort_values(by=\"Date\")\n",
    "      level_df_pivoted = level_df_pivoted.groupby(\"Date\").mean(\"Level\").reset_index()\n",
    "\n",
    "      comb = df_salmon.merge(df_temp[[\"UTC_DATE\", \"TEMP\"]], left_on=\"date\", right_on=\"UTC_DATE\", how=\"right\")\n",
    "      comb = comb.drop([\"date\"], axis=1)\n",
    "      comb[\"count\"] = comb[\"count\"].fillna(0)\n",
    "      comb = comb.rename(columns={\"UTC_DATE\": \"date\"})\n",
    "      comb[\"date\"] = pd.to_datetime(comb[\"date\"])\n",
    "      comb[\"month\"] = comb[\"date\"].dt.month\n",
    "      comb[\"year\"] = comb[\"date\"].dt.year\n",
    "\n",
    "      comb_df = comb.merge(flow_df_pivoted, left_on=\"date\", right_on=\"Date\")\n",
    "      comb_df = comb_df.merge(level_df_pivoted, left_on=\"date\", right_on=\"Date\")\n",
    "      keep_cols = [\"date\",\"month\", \"year\",  \"TEMP\", \"Flow\", \"Level\", \"count\"]\n",
    "      comb_df = comb_df[keep_cols]\n",
    "      comb_df = comb_df.rename(columns={\"TEMP\": \"Temp\"})\n",
    "\n",
    "      month_key = {\n",
    "            1: \"january\",\n",
    "            2: \"feburary\",\n",
    "            3: \"march\",\n",
    "            4: \"april\",\n",
    "            5: \"may\",\n",
    "            6: \"june\",\n",
    "            7: \"july\",\n",
    "            8: \"august\",\n",
    "            10: \"october\",\n",
    "            11: \"november\",\n",
    "            12: \"december\"}\n",
    "      \n",
    "      def parse_variables(df, variable, months, dict_key=month_key):\n",
    "\n",
    "            for month in months:\n",
    "                  df[f\"{dict_key[month]}_{variable}\"] = 0\n",
    "\n",
    "            for year in df[\"year\"].unique().tolist():\n",
    "\n",
    "                  for month in months:\n",
    "                        if month == 1 or month == 2:\n",
    "                              temp_df = df[df[\"year\"] == year]\n",
    "                        else:\n",
    "                              temp_df = df[df[\"year\"] == year-1]\n",
    "                        month_df = temp_df[temp_df[\"month\"] == month]\n",
    "                        month_avg = month_df[f\"{variable}\"].mean()\n",
    "\n",
    "                        df.loc[(df[\"year\"] == year), f\"{dict_key[month]}_{variable}\"] = month_avg\n",
    "\n",
    "            return df\n",
    "      \n",
    "      new_df = parse_variables(comb_df, \"Flow\", [10,11])\n",
    "      new_df = parse_variables(new_df, \"Temp\", [12, 1, 2])\n",
    "      new_df = parse_variables(new_df, \"Level\", [10, 11])\n",
    "\n",
    "      def parse_rolling_means(df, variable, mean_metric, window_start, window_end):\n",
    "            diff = window_start - window_end\n",
    "            df[f\"rolling_{variable}_{mean_metric}_{diff}\"] = 0\n",
    "\n",
    "            for ind, row in df.iterrows():\n",
    "                  if ind <= window_start:\n",
    "                        df[f\"rolling_{variable}_{mean_metric}_{diff}\"] = None\n",
    "                  else:\n",
    "                        recent_window_days = df.iloc[(ind-window_start):(ind-window_end),:]\n",
    "                        if mean_metric == \"mean\":\n",
    "                              avg_var_value = recent_window_days[variable].mean()\n",
    "                        else:\n",
    "                              avg_var_value = recent_window_days[variable].std()\n",
    "                        df.loc[ind, f\"rolling_{variable}_{mean_metric}_{diff}\"] = avg_var_value\n",
    "            \n",
    "            return df\n",
    "\n",
    "      new_df = parse_rolling_means(new_df, \"Temp\", \"mean\", 45, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Temp\", \"mean\", 40, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Temp\", \"mean\", 35, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Flow\", \"mean\", 45, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Flow\", \"mean\", 40, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Flow\", \"mean\", 35, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Level\", \"mean\", 45, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Level\", \"mean\", 40, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Level\", \"mean\", 35, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Temp\", \"std\", 45, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Temp\", \"std\", 40, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Temp\", \"std\", 35, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Flow\", \"std\", 45, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Flow\", \"std\", 40, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Flow\", \"std\", 35, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Level\", \"std\", 45, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Level\", \"std\", 40, 30)\n",
    "      new_df = parse_rolling_means(new_df, \"Level\", \"std\", 35, 30)\n",
    "\n",
    "      missing_cols = new_df.columns[new_df.isna().any()].tolist()\n",
    "\n",
    "      for col in missing_cols:\n",
    "            median_value = new_df[col].median()\n",
    "            new_df[col].fillna(median_value, inplace=True)\n",
    "      \n",
    "      return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'month', 'year', 'Temp', 'Flow', 'Level', 'count',\n",
      "       'october_Flow', 'november_Flow', 'december_Temp', 'january_Temp',\n",
      "       'feburary_Temp', 'october_Level', 'november_Level',\n",
      "       'rolling_Temp_mean_15', 'rolling_Temp_mean_10', 'rolling_Temp_mean_5',\n",
      "       'rolling_Flow_mean_15', 'rolling_Flow_mean_10', 'rolling_Flow_mean_5',\n",
      "       'rolling_Level_mean_15', 'rolling_Level_mean_10',\n",
      "       'rolling_Level_mean_5', 'rolling_Temp_std_15', 'rolling_Temp_std_10',\n",
      "       'rolling_Temp_std_5', 'rolling_Flow_std_15', 'rolling_Flow_std_10',\n",
      "       'rolling_Flow_std_5', 'rolling_Level_std_15', 'rolling_Level_std_10',\n",
      "       'rolling_Level_std_5'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Flow</th>\n",
       "      <th>Level</th>\n",
       "      <th>count</th>\n",
       "      <th>october_Flow</th>\n",
       "      <th>november_Flow</th>\n",
       "      <th>december_Temp</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_Level_mean_5</th>\n",
       "      <th>rolling_Temp_std_15</th>\n",
       "      <th>rolling_Temp_std_10</th>\n",
       "      <th>rolling_Temp_std_5</th>\n",
       "      <th>rolling_Flow_std_15</th>\n",
       "      <th>rolling_Flow_std_10</th>\n",
       "      <th>rolling_Flow_std_5</th>\n",
       "      <th>rolling_Level_std_15</th>\n",
       "      <th>rolling_Level_std_10</th>\n",
       "      <th>rolling_Level_std_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-09-02</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>19.127273</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.5480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.679129</td>\n",
       "      <td>28.3825</td>\n",
       "      <td>3.965188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8237</td>\n",
       "      <td>2.160008</td>\n",
       "      <td>1.950006</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.041962</td>\n",
       "      <td>1.416962</td>\n",
       "      <td>0.74561</td>\n",
       "      <td>0.060489</td>\n",
       "      <td>0.042766</td>\n",
       "      <td>0.024903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-09-03</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>18.045833</td>\n",
       "      <td>0.7905</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.679129</td>\n",
       "      <td>28.3825</td>\n",
       "      <td>3.965188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8237</td>\n",
       "      <td>2.160008</td>\n",
       "      <td>1.950006</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.041962</td>\n",
       "      <td>1.416962</td>\n",
       "      <td>0.74561</td>\n",
       "      <td>0.060489</td>\n",
       "      <td>0.042766</td>\n",
       "      <td>0.024903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-09-04</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>17.062500</td>\n",
       "      <td>0.7490</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.679129</td>\n",
       "      <td>28.3825</td>\n",
       "      <td>3.965188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8237</td>\n",
       "      <td>2.160008</td>\n",
       "      <td>1.950006</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.041962</td>\n",
       "      <td>1.416962</td>\n",
       "      <td>0.74561</td>\n",
       "      <td>0.060489</td>\n",
       "      <td>0.042766</td>\n",
       "      <td>0.024903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-09-05</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>16.837500</td>\n",
       "      <td>0.6945</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.679129</td>\n",
       "      <td>28.3825</td>\n",
       "      <td>3.965188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8237</td>\n",
       "      <td>2.160008</td>\n",
       "      <td>1.950006</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.041962</td>\n",
       "      <td>1.416962</td>\n",
       "      <td>0.74561</td>\n",
       "      <td>0.060489</td>\n",
       "      <td>0.042766</td>\n",
       "      <td>0.024903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-09-06</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>16.954167</td>\n",
       "      <td>0.6680</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.679129</td>\n",
       "      <td>28.3825</td>\n",
       "      <td>3.965188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8237</td>\n",
       "      <td>2.160008</td>\n",
       "      <td>1.950006</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.041962</td>\n",
       "      <td>1.416962</td>\n",
       "      <td>0.74561</td>\n",
       "      <td>0.060489</td>\n",
       "      <td>0.042766</td>\n",
       "      <td>0.024903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  month  year       Temp    Flow   Level  count  october_Flow  \\\n",
       "0 2013-09-02      9  2013  19.127273  0.8755  0.5480    0.0      7.679129   \n",
       "1 2013-09-03      9  2013  18.045833  0.7905  0.5405    0.0      7.679129   \n",
       "2 2013-09-04      9  2013  17.062500  0.7490  0.5365    0.0      7.679129   \n",
       "3 2013-09-05      9  2013  16.837500  0.6945  0.5300    0.0      7.679129   \n",
       "4 2013-09-06      9  2013  16.954167  0.6680  0.5280    0.0      7.679129   \n",
       "\n",
       "   november_Flow  december_Temp  ...  rolling_Level_mean_5  \\\n",
       "0        28.3825       3.965188  ...                0.8237   \n",
       "1        28.3825       3.965188  ...                0.8237   \n",
       "2        28.3825       3.965188  ...                0.8237   \n",
       "3        28.3825       3.965188  ...                0.8237   \n",
       "4        28.3825       3.965188  ...                0.8237   \n",
       "\n",
       "   rolling_Temp_std_15  rolling_Temp_std_10  rolling_Temp_std_5  \\\n",
       "0             2.160008             1.950006            1.571429   \n",
       "1             2.160008             1.950006            1.571429   \n",
       "2             2.160008             1.950006            1.571429   \n",
       "3             2.160008             1.950006            1.571429   \n",
       "4             2.160008             1.950006            1.571429   \n",
       "\n",
       "   rolling_Flow_std_15  rolling_Flow_std_10  rolling_Flow_std_5  \\\n",
       "0             2.041962             1.416962             0.74561   \n",
       "1             2.041962             1.416962             0.74561   \n",
       "2             2.041962             1.416962             0.74561   \n",
       "3             2.041962             1.416962             0.74561   \n",
       "4             2.041962             1.416962             0.74561   \n",
       "\n",
       "   rolling_Level_std_15  rolling_Level_std_10  rolling_Level_std_5  \n",
       "0              0.060489              0.042766             0.024903  \n",
       "1              0.060489              0.042766             0.024903  \n",
       "2              0.060489              0.042766             0.024903  \n",
       "3              0.060489              0.042766             0.024903  \n",
       "4              0.060489              0.042766             0.024903  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salmon_path = \"salmon_concat.csv\"\n",
    "temp_path = \"northcochiwan_daily_temp-2.csv\"\n",
    "flow_path = \"flow_2023.csv\"\n",
    "level_path = \"level_2023.csv\"\n",
    "\n",
    "final_df = preprocessing(salmon_path, temp_path, level_path, flow_path)\n",
    "print(final_df.columns)\n",
    "final_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mds574",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
